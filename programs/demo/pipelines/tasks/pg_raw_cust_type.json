{
  "login_id": "freddie",
  "id": 441,
  "project_name": "demo",
  "pipeline_name": "demo_customer",
  "project_id": 64,
  "pipeline_id": 164,
  "task_name": "pg_raw_cust_type",
  "task_description": "Load from s3 into postgres",
  "task_type": "Ingestion",
  "task_sequence": "\"435\"",
  "updated_dttm": "2023-12-28T12:32:41.000Z",
  "source": "AWS S3",
  "target": "PostgreSQL",
  "is_active": "Y",
  "created_by": "Puneeth",
  "updated_by": "prajwal",
  "task": {
    "source": {
      "source_type": "aws_s3_read",
      "header": "Y",
      "encoding": "utf-8",
      "delimiter": ",",
      "file_name": "cust_typ_*.csv",
      "file_path": "demo/landing/",
      "file_type": "csv",
      "chunk_size": 10000,
      "quote_char": "\"",
      "compression": "",
      "escape_char": "\\",
      "skip_footer": null,
      "skip_header": null,
      "alias_columns": null,
      "parameter_type": "AWS S3",
      "select_columns": null,
      "connection_name": "aws_connection_test"
    },
    "target": {
      "target_type": "postgres_write",
      "schema": "raw",
      "operation": "replace",
      "table_name": "customer_type",
      "audit_columns": "active",
      "parameter_type": "PostgreSQL",
      "connection_name": "ec2_postgres",
      "target_max_record_count": null
    },
    "data_quality_execution": {
      "pre_check_enable": "N",
      "post_check_enable": "N"
    }
  }
}