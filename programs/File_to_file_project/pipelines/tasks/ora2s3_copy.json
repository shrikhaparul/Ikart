{
  "login_id": "jjones",
  "id": 580,
  "project_name": "File_to_file_project",
  "pipeline_name": "Files_tranfer",
  "project_id": 73,
  "pipeline_id": 173,
  "task_name": "ora2s3_copy",
  "task_description": "ingesting data using oracle to  aws s3",
  "task_type": "Bulk Ingestion",
  "task_sequence": "0",
  "updated_dttm": "2024-05-07T18:48:42.000Z",
  "source": "DB",
  "target": "Files",
  "is_active": "Y",
  "created_by": "jjones",
  "updated_by": "jjones",
  "chunk_size": 100000,
  "source_type": "DB",
  "target_type": "Files",
  "job_execution": "SeaTunnel",
  "restartability": "begin",
  "task": {
    "details": [
      {
        "subtask": "1",
        "source": {
          "task_group": "6",
          "connection_name": "Oracle",
          "object_name": "AGG_SALES1CSV",
          "object_type": "Table",
          "schema_name": "TEST",
          "database_name": "XEPDB1",
          "extraction_type": "Full",
          "extraction_criteria": ""
        },
        "target": {
          "header": "Y",
          "connection_name": "aws_S3_conn_files_to_files",
          "encoding": "utf-8",
          "delimiter": "",
          "file_path": "Excel_folder/files/Output_data/oracle/",
          "object_name": "AGG_SALES1CSV",
          "primary_key": "",
          "schema_name": "demo",
          "audit_fields": "no",
          "action_on_table": "CREATE IF NOT EXIST",
          "object_sufix_name": "%DD%%MM%%YYYY%",
          "object_prefix_name": "Target_",
          "target_file_format": "excel"
        }
      }
    ]
  }
}